# checks how many flows seen by slips are also present in sucata's eve.log
import ipaddress

db = '/home/alya/Desktop/IDPS-Comparison-Tool/dataset/test7-malicious-pcap/slips/flows.sqlite'


# db = '/home/alya/Desktop/IDPS-Comparison-Tool/dataset/CTU-Malware-Capture-Botnet-4/slips-after-modifying-cid/flows.sqlite'
sur = '/home/alya/Desktop/IDPS-Comparison-Tool/dataset/test7-malicious-pcap/suricata/eve.json'


from database.sqlite_db import SQLiteDB
from termcolor import colored
from threading import Lock
from time import sleep
import json
import sqlite3

class SlipsParser:
	name = "Slips"
	# used to lock each call to commit()
	cursor_lock = Lock()

	def __init__(self, slips_db: str):
		# this has to be the path of the sqlite3 db generated by slips with all the labels and community IDs
		self.slips_db: str = slips_db

	def log(self, green_txt, normal_txt):
		normal_txt = str(normal_txt)
		green_txt = str(green_txt)

		print(colored(f'[{self.name}] ', 'blue') + colored(green_txt,'green') + normal_txt)

	def connect(self):
		self.conn = sqlite3.connect(self.slips_db, check_same_thread=False)
		self.conn.row_factory = sqlite3.Row

		self.cursor = self.conn.cursor()

	def iterate_flows(self, table):
		"""returns an iterator for all rows in the flows table in slips db"""
		# generator function to iterate over the rows
		def row_generator():
			# select all flows and altflows
			self.execute(f'SELECT * FROM {table};')

			while True:
				row = self.fetchone()
				if row is None:
					break
				yield dict(row)

		# Return the combined iterator
		return iter(row_generator())


	def fetchone(self):
		"""
		wrapper for sqlite fetchone to be able to use a lock
		"""
		self.cursor_lock.acquire(True)
		res = self.cursor.fetchone()
		self.cursor_lock.release()
		return res

	def execute(self, query, params=None):
		"""
		wrapper for sqlite execute() To avoid 'Recursive use of cursors not allowed' error
		and to be able to use a Lock()
		since sqlite is terrible with multi-process applications
		this should be used instead of all calls to commit() and execute()
		"""

		try:
			self.cursor_lock.acquire(True)

			if not params:
				self.cursor.execute(query)
			else:
				self.cursor.execute(query, params)
			self.conn.commit()

			self.cursor_lock.release()
		except sqlite3.Error as e:
			if "database is locked" in str(e):
				self.cursor_lock.release()
				# Retry after a short delay
				sleep(0.1)
				self.execute(query, params=params)
			else:
				# An error occurred during execution
				print(f"Error executing query ({query}): {e}")

	def check_if_cid_in_db(self, cid, db):
		"""checks if the given comunity id is present in the given table"""
		self.execute(f'SELECT * FROM {db} WHERE community_id = "{cid}";')
		if self.fetchone():
			return True
		return False

	def parse(self):
		"""reads the output db of slips with the labels and stores it in this tools' db"""
		# connect to the given db
		self.connect()
		flows_count = 0
		for row in self.iterate_flows('flows'):
			flows_count += 1
			# each row is a dict
			flow = {
				'community_id': row['community_id'],
				'label' : row['label']
			}
			# self.log(f"Extracted slips label for flow: ", f"{row['community_id']}")
			yield flow


		# for row in self.iterate_flows('altflows'):
		#     flows_count += 1
		#     # each row is a dict
		#     flow = {
		#         'community_id': row['community_id'],
		#         'label' : row['label']
		#     }
		#     # self.log(f"Extracted slips label for flow: ", f"{row['community_id']}")
		#     yield flow
	def fetchall(self):
		"""
		wrapper for sqlite fetchall to be able to use a lock
		"""
		self.cursor_lock.acquire(True)
		res = self.cursor.fetchall()
		self.cursor_lock.release()
		return res

	def get_flow(self, srcip, dstip, srcport, dstport, proto):
		"""
		given all the fields used in the cid, try to get this flow from the db of slips and get the cid generated by slips of it 
		"""
		self.execute(f'SELECT * FROM flows;')

		saddr_obj = ipaddress.IPv6Address(srcip)
		saddr_no_leading_zeros = saddr_obj.compressed

		daddr_obj = ipaddress.IPv6Address(dstip)
		daddr_no_leading_zeros = daddr_obj.compressed

		for flow in self.fetchall():
			cid = flow[5]			
			flow = json.loads(flow[1])
			# print(".. now reading this slips flow")
			# print(flow)
			if (flow['sport'] == srcport 
				and flow['dport'] == dstport 
				and flow['saddr'] == saddr_no_leading_zeros 
				and flow['daddr'] == daddr_no_leading_zeros
				and flow['proto'] == proto
				):
				return flow, cid



parserr = SlipsParser(db)

with open(sur, 'r') as f:
	with open("/home/alya/Desktop/IDPS-Comparison-Tool/missed_lines_test7",'w') as w:
		tot_suricata_lines = 0 
		tot_matching_cids = 0	

		while line := f.readline():
			# by suricata
			line = json.loads(line)
			try:
				cid = line['community_id']
			except:
				import sys
				sys.exit()
			# now we're sure that all th eprinted stats will ignore timeout flows
			tot_suricata_lines += 1 

			# # ignore lines with reason= timeout
			# if 'flow' in line:
			# 	flow = line['flow']
			# 	if 'reason' in flow and flow['reason'] == 'timeout':
			# 		timeout_flows += 1
			# 		continue

			# check law suricata's cid mwgod f db slips 
			for flow in parserr.parse():
				if 	parserr.check_if_cid_in_db(cid, 'flows') :
					tot_matching_cids +=  1 
					missed = tot_suricata_lines - tot_matching_cids
					print(f" {cid} found by suricata is also found by slips. total matching cids: {tot_matching_cids} \
						 tot_suricata_lines read: {tot_suricata_lines}\n lines in suricata but not in slips: {missed}")

					break

			else:
				# print(line)
				json.dump(line, w)
				w.write('\n')

				print(f'Suricataline : {line}\n')
				# now try to find the flow in slips db to print the cid slips generated
				if 'icmp' not in line['proto'].lower():
					flow, cid = parserr.get_flow(line['src_ip'], line['dest_ip'], line['src_port'], line['dest_port'], line['proto'].lower())

					if flow: 
						print(f'Slips line: {flow} , {cid}')
					else:
						print("couldn't find the same flow in slips db")
				else:
					print(f"ICMP FLOW NOT FOUND IN SLIPS????")
				print('')
				missed = tot_suricata_lines - tot_matching_cids
				print(f" {cid} found by suricata is not found by slips. total matching cids: {tot_matching_cids} \
					 tot_suricata_lines read: {tot_suricata_lines}\n  lines in suricata but not in slips: {missed}")


			print('*'*50)

